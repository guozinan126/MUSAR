# MUSAR
<a href="https://arxiv.org/abs/2505.02823"><img src="https://img.shields.io/badge/ariXv-2411.15098-A42C25.svg" alt="arXiv"></a>
<a href="https://huggingface.co/datasets/guozinan/MUSAR-Gen"><img src="https://img.shields.io/badge/ü§ó_HuggingFace-Dataset-ffbd45.svg" alt="HuggingFace"></a>
> **MUSAR: Exploring Multi-Subject Customization from Single-Subject Dataset via Attention Routing**
> <br>
> Zinan Guo, 
> Pengze Zhang, 
> Yanze Wu‚úù, 
> Chong Mou, 
> Songtao Zhao,
> Qian He
> <br>
> (‚úù Corresponding Author) <br>
> Bytedance Intelligent Creation
> <br>

![Teaser](https://github.com/user-attachments/assets/69612922-7046-41b6-9f89-6c56c736ece7)

# [MUSAR-Gen](https://huggingface.co/datasets/guozinan/MUSAR-Gen) Dataset

‚≠êÔ∏è Although MUSAR is trained solely on diptych data constructed from concatenated single-subject samples, we recognize that a high-quality multi-subject paired dataset is highly beneficial for the field of image customization. To accelerate progress in this field, **we are releasing the high-quality multi-subject dataset generated by MUSAR: [MUSAR-Gen](https://huggingface.co/datasets/guozinan/MUSAR-Gen).** It delivers FLUX-comparable image quality without exhibiting attribute entanglement issues. Hope it will be helpful to researchers working on related topics.

![Dataset](https://github.com/user-attachments/assets/13380c72-ae46-42db-9943-8162f6fd04fa)

## dataset info
Construction details: The condition images are two subjects randomly selected from the [subjects200k](https://huggingface.co/datasets/Yuanshi/Subjects200K) dataset (excluding the 111,761 subjects used during the model training process). The prompt format is: "An undivided, seamless, and harmonious picture with two objects. in the xxx scene, Subject A and Subject B are placed together." By collecting the outputs of the MUSAR model, we obtained approximately 30,000 samples.


### Quick Start
- Load dataset
  ```python
  from datasets import load_dataset
  # Load dataset
  dataset = load_dataset('guozinan/MUSAR-Gen')

### Data Format
  | Key name             | Type    | Description                                                     |
  | -------------------- | ------- |-----------------------------------------------------------------|
  | `cond_img_0`         | `image` | Reference Image Information (First Image).                      |
  | `cond_img_1`         | `image` | Reference Image Information (Second Image).                     |
  | `tgt_img`            | `image` | Multi-subject customized result generated by the MUSAR model.   |
  | `cond_prompt_0`      | `str`   | Textual description of the corresponding subject in cond_img_0. |
  | `cond_prompt_1`      | `str`   | Textual description of the corresponding subject in cond_img_0. |
  | `prompt`             | `str`   | Textual description of the tgt_img content.                     |

## Citation
If you find this paper useful for your research or use MUSAR-Gen dataset, please consider citing our paper:
```
@article{guo2025musar,
  title={MUSAR: Exploring Multi-Subject Customization from Single-Subject Dataset via Attention Routing},
  author={Guo, Zinan and Zhang, Pengze and Wu, Yanze and Mou, Chong and Zhao, Songtao and He, Qian},
  journal={arXiv preprint arXiv:2505.02823},
  year={2025}
}
```